{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1aa7201",
   "metadata": {},
   "source": [
    "# Homework 5 - Naive Bayes\n",
    "\n",
    "Make sure you have downloaded:\n",
    "- heart_processed.csv\n",
    "\n",
    "This homework will ask you to implement naive bayes using a custom likelihood and then comparing it against sklearn's Gaussian naive Bayes. \n",
    "\n",
    "The execution is slightly different from lecture and section. \n",
    "- It is more streamlined to take adavantage of vector multiplications and numpy functions, which has its own benefits if we want to scale up our naive bayes prediction to higher dimensions. \n",
    "- However, you may need to familiarize yourself with the \"dictionary\" data structure.\n",
    "\n",
    "Before attempting this homework, make sure you understand the broad strokes of naive Bayes. This will make your coding and debugging much smoother."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d2714",
   "metadata": {},
   "source": [
    "## 0 Data\n",
    "Load `heart_processed.csv` from the [Heart Failure Clinical Records Dataset](https://archive.ics.uci.edu/ml/datasets/Heart%2Bfailure%2Bclinical%2Brecords)  It contains various predictors (which are in log-scale) for predicting the event of death `DEATH_EVENT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a787dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c6d33",
   "metadata": {},
   "source": [
    "Before submitting your homework, remember to set:\n",
    "- random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f648bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shapes:\n",
      "\t X_train -> (209, 6)\n",
      "\t y_train -> (209,)\n",
      "test shapes:\n",
      "\t X_test -> (90, 6)\n",
      "\t y_test -> (90,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.317488</td>\n",
       "      <td>6.366470</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>12.487485</td>\n",
       "      <td>0.641854</td>\n",
       "      <td>4.867534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.007333</td>\n",
       "      <td>8.969669</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>12.481270</td>\n",
       "      <td>0.095310</td>\n",
       "      <td>4.912655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.174387</td>\n",
       "      <td>4.983607</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>11.995352</td>\n",
       "      <td>0.262364</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.912023</td>\n",
       "      <td>4.709530</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>12.254863</td>\n",
       "      <td>0.641854</td>\n",
       "      <td>4.919981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.174387</td>\n",
       "      <td>5.075174</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>12.697715</td>\n",
       "      <td>0.993252</td>\n",
       "      <td>4.753590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>4.127134</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>11.951180</td>\n",
       "      <td>0.095310</td>\n",
       "      <td>4.962845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4.007333</td>\n",
       "      <td>7.506592</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>12.506177</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>4.934474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>3.806662</td>\n",
       "      <td>7.630461</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>13.517105</td>\n",
       "      <td>-0.223144</td>\n",
       "      <td>4.927254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>3.806662</td>\n",
       "      <td>7.788626</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>11.849398</td>\n",
       "      <td>0.336472</td>\n",
       "      <td>4.941642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>3.912023</td>\n",
       "      <td>5.278115</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>12.886641</td>\n",
       "      <td>0.470004</td>\n",
       "      <td>4.912655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  creatinine_phosphokinase  ejection_fraction  platelets  \\\n",
       "0    4.317488                  6.366470           2.995732  12.487485   \n",
       "1    4.007333                  8.969669           3.637586  12.481270   \n",
       "2    4.174387                  4.983607           2.995732  11.995352   \n",
       "3    3.912023                  4.709530           2.995732  12.254863   \n",
       "4    4.174387                  5.075174           2.995732  12.697715   \n",
       "..        ...                       ...                ...        ...   \n",
       "294  4.127134                  4.110874           3.637586  11.951180   \n",
       "295  4.007333                  7.506592           3.637586  12.506177   \n",
       "296  3.806662                  7.630461           4.094345  13.517105   \n",
       "297  3.806662                  7.788626           3.637586  11.849398   \n",
       "298  3.912023                  5.278115           3.806662  12.886641   \n",
       "\n",
       "     serum_creatinine  serum_sodium  DEATH_EVENT  \n",
       "0            0.641854      4.867534            1  \n",
       "1            0.095310      4.912655            1  \n",
       "2            0.262364      4.859812            1  \n",
       "3            0.641854      4.919981            1  \n",
       "4            0.993252      4.753590            1  \n",
       "..                ...           ...          ...  \n",
       "294          0.095310      4.962845            0  \n",
       "295          0.182322      4.934474            0  \n",
       "296         -0.223144      4.927254            0  \n",
       "297          0.336472      4.941642            0  \n",
       "298          0.470004      4.912655            0  \n",
       "\n",
       "[299 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"heart_processed_log.csv\", index_col=0)\n",
    "X = dataset.drop(\"DEATH_EVENT\", axis=1).values\n",
    "y = dataset[\"DEATH_EVENT\"].values\n",
    "\n",
    "# split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# print the shapes of the training and testing sets\n",
    "print('train shapes:')\n",
    "print('\\t X_train ->', X_train.shape)\n",
    "print('\\t y_train ->', y_train.shape)\n",
    "\n",
    "print('test shapes:')\n",
    "print('\\t X_test ->', X_test.shape)\n",
    "print('\\t y_test ->', y_test.shape)\n",
    "\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e9531e",
   "metadata": {},
   "source": [
    "Recall: naive Bayes is choosing the class $k$, $C_k$, that maximizes the posterior\n",
    "$$\n",
    "P(C_k \\lvert\\,\\boldsymbol{x}) = \\frac{\\pi(C_k)\\,{\\cal{}L}_{\\!\\boldsymbol{x}}(C_k)}{Z}.\n",
    "$$\n",
    "Hence, we maximize the numerator + assume that all $d$ features $x_i$ are independent (\"naive-ness\"). So we want to find the $k$ that satisfies\n",
    "$$\n",
    "\\max_k \\, \\pi(C_k)\\,{\\cal{}L}_{\\!\\boldsymbol{x}}(C_k) \\quad = \\quad \\max_k \\, \\left( \\pi(C_k)\\,\\prod_{i=1}^d p(x_i \\lvert C_k) \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4be0c2",
   "metadata": {},
   "source": [
    "## 1 Custom Naive Bayes Classifier with KDE\n",
    "You will create a naive Bayes classifier:\n",
    "- using the training data\n",
    "- with KDE to approximate the likelihood\n",
    "- with bernoulli as the prior\n",
    "\n",
    "**Use only the training data ```X_train, y_train``` to fit the naive Bayes classifier.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980cca8",
   "metadata": {},
   "source": [
    "### 1.1 Prior\n",
    "1. [2 pt] Compute ```prior```, a two element array. \n",
    "    - prior[0] is the probability of death event 0, $\\pi(C_0)$\n",
    "    - prior[1] is the probability of death event 1, $\\pi(C_1)$ \n",
    "    - You should construct the prior probabilities based on frequency of death events from the training data. \n",
    "    - Tip: Use np.unique() with return_counts.\n",
    "2. [1 pt] Print ```prior```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227c44b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probability for 0: 0.6746411483253588\n",
      "Prior probability for 1: 0.3253588516746411\n"
     ]
    }
   ],
   "source": [
    "#create a labels array and a counts array and update both in one single line of code\n",
    "unique_labels, label_counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "\n",
    "# Calculate prior probabilities\n",
    "prior = label_counts / len(y_train)\n",
    "\n",
    "#Iterate through unique_labels and prior arrays simulataneously to output results\n",
    "for label, prob in zip(unique_labels, prior):\n",
    "    print(f\"Prior probability for {label}: {prob}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeefe43",
   "metadata": {},
   "source": [
    "### 1.2 Likelihood (KDE)\n",
    "1. [2 pt] Define dictionaries `kde0` and `kde1` which fulfill the following:\n",
    "    - kde0[i] corresponds to the kde object (created by calling `scipy.stats.gaussian_kde`) for feature i when death event is 0. kde1[i] defined likewise.\n",
    "    - Make sure you index the correct rows of `X_train` when defining kdes.\n",
    "    - Use bandwidth method 'scott'. (For fun, you can try 'silverman' and see what difference in result you get.)\n",
    "    - As with all arrays you throw into sklearn or scipy, you may need to take transposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2818202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "kde0 = {} \n",
    "kde1 = {} \n",
    "\n",
    "X_train_death_0 = X_train[y_train == 0]\n",
    "X_train_death_1 = X_train[y_train == 1]\n",
    "\n",
    "for i in range(X_train_death_0.shape[1]):\n",
    "    \n",
    "    # Create Gaussian KDE for death event 0 with 'scott' bandwidth\n",
    "    kde0[i] = gaussian_kde(X_train_death_0[:,i].T, bw_method='scott')\n",
    "\n",
    "    \n",
    "    # Create Gaussian KDE for death event 1 with 'scott' bandwidth\n",
    "    kde1[i] = gaussian_kde(X_train_death_1[:,i].T, bw_method='scott')\n",
    "\n",
    "print(X_train.shape[0])\n",
    "#print(X_train_death_0[:,0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2650786a",
   "metadata": {},
   "source": [
    "2. [2 pt] Complete the code for ```compute_likelihood``` function.\n",
    "    - The objects kde0[i] and kde1[i] have a method .pdf(), which you will use when computing the likelihood.\n",
    "        - Read the documentation to understand how it works.\n",
    "    - `likelihood0[j]` is the likleihood of seeing $j$ th data $\\boldsymbol{x_j} = \\left(\\boldsymbol{x_j}_1, \\dots, \\boldsymbol{x_j}_d\\right)$ for death event 0, i.e., ${\\cal{}L}_{\\!\\boldsymbol{x_j}}(C_0) = \\prod_{i=1}^d p(\\boldsymbol{x_j}_i \\lvert C_0)$\n",
    "    - `likelihood1[j]` defined likewise.\n",
    "    - You can loop over the kde objects kde[i] to populate the likelihood arrays.\n",
    "\n",
    "(Your solution shouldn't be very complicated. A working solutions needs only about 5-10 lines of code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6afc97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood(x, kde0, kde1):\n",
    "    # input:    x, a (# data) by (# features) array of test data\n",
    "    #           kde0 and kde1, dictionaries that will be used to compute the likelihood\n",
    "    # output:   likelihood, a (# data) by (# classes) array. \n",
    "    #           likelihood[j,k] is the likelihood of data j given class k\n",
    "    \n",
    "    # likelihood0[j] is the likelihood of data j given class 0. Analogously for likelihood1\n",
    "    likelihood0 = np.ones(x.shape[0])    # TODO\n",
    "    likelihood1 = np.ones(x.shape[0])    # TODO\n",
    "\n",
    "    for i in range(x.shape[1]):\n",
    "        likelihood0 *= kde0[i].pdf(x[:, i])\n",
    "        likelihood1 *= kde1[i].pdf(x[:, i])\n",
    "\n",
    "    likelihood = np.vstack((likelihood0, likelihood1)).T\n",
    "    \n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecf5b7a",
   "metadata": {},
   "source": [
    "### 1.3 Posterior\n",
    "1. [2 pt] Complete the code for ```compute_posterior``` function. \n",
    "    - It should include calling the function ```compute_likelihood```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdabfd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_posterior(x, prior, kde0, kde1):\n",
    "    # input:    x, a (# data) by (# features) array of test data\n",
    "    #           prior, a 1 by 2 array\n",
    "    #           kde0 and kde1, kde dictionaries that will be used to compute the likelihood\n",
    "    # output:   posterior, a (# data) by (# classes) array\n",
    "\n",
    "    likelihood = compute_likelihood(x, kde0, kde1)       # TODO\n",
    "    posterior  = prior * likelihood      # TODO\n",
    "\n",
    "    return posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4126c3",
   "metadata": {},
   "source": [
    "### 1.4 Combine prior, likelihood, posterior\n",
    "Now, we are ready to piece all the code we prepared above.\n",
    "1. [2 pt] Complete the code for ```naive_bayes_predict```.\n",
    "    - Your code should include calling the ```compute_posterior``` function.\n",
    "    - Computing y_pred should be a simple one line of code. You may consider using numpy functions that find the index of the largest entry on every row.\n",
    "2. [1 pt] Complete the code for ```print_success_rates```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "362e2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(x, prior, kde0, kde1):\n",
    "    # input:    x, a (# data) by (# features) array\n",
    "    #           prior, a 1 by 2 array\n",
    "    #           kde0 and kde1, kde dictionaries that will be used to compute the likelihood\n",
    "    # output:   y_pred, an array of length (# data)\n",
    "    \n",
    "    posterior = compute_posterior(x, prior, kde0, kde1)        # TODO\n",
    "    y_pred    = np.argmax(posterior, axis=1)        # TODO\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def print_success_rates(y_true,y_pred):\n",
    "    n_success = np.sum(y_true == y_pred)        # TODO\n",
    "    n_total   = len(y_true)        # TODO\n",
    "\n",
    "    print(\"Number of correctly labeled points: %d of %d.  Accuracy: %.2f\" \n",
    "        % (n_success, n_total, n_success/n_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e39a565",
   "metadata": {},
   "source": [
    "### 1.5 Predict\n",
    "1. [1 pt] Use your custom naive Bayes to:\n",
    "    - predict *TRAINING* \n",
    "    - print the results with ```print_success_rates```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b05d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correctly labeled points: 171 of 209.  Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# TODO predict training data and print\n",
    "\n",
    "# Predict on training data\n",
    "y_pred_train = naive_bayes_predict(X_train, prior, kde0, kde1)\n",
    "\n",
    "print_success_rates(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489ddcd",
   "metadata": {},
   "source": [
    "2. [1 pt] Use your custom naive Bayes to:\n",
    "    - predict *TEST* data\n",
    "    - print the results with ```print_success_rates```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e984d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correctly labeled points: 67 of 90.  Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "# TODO predict test data and print\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = naive_bayes_predict(X_test, prior, kde0, kde1)\n",
    "\n",
    "print_success_rates(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703d41af",
   "metadata": {},
   "source": [
    "## 2. sklearn Gaussian naive Bayes\n",
    "Let's compare our custom naive Bayes with KDE to the sklearn Gaussian naive Bayes.\n",
    "\n",
    "### 2.1 Train\n",
    "1. [1 pt] Fit ```gnb``` using training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a53e36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run sklearn's version - read up on differences if interested\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create a Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Fit the model to the training data\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c1058",
   "metadata": {},
   "source": [
    "### 2.2 Predict\n",
    "1. [1 pt] Use sklearn naive Bayes to:\n",
    "    - predict *TRAINING* data\n",
    "    - print the results with ```print_success_rates```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "618cb163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correctly labeled points: 160 of 209.  Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# TODO predict training data and print\n",
    "\n",
    "# Predict on training data\n",
    "y_pred_train_sklearn = gnb.predict(X_train)\n",
    "\n",
    "print_success_rates(y_train, y_pred_train_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c77a88",
   "metadata": {},
   "source": [
    "2. [1 pt] Use sklearn naive Bayes to:\n",
    "    - predict *TEST* data\n",
    "    - print the results with ```print_success_rates```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18d00bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correctly labeled points: 68 of 90.  Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "# TODO predict test data and print\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test_sklearn = gnb.predict(X_test)\n",
    "\n",
    "print_success_rates(y_test, y_pred_test_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a457e2dd",
   "metadata": {},
   "source": [
    "## 3. Discussion\n",
    "### 3.1 random_state = 0\n",
    "Using random_state=0 and respond to the following questions.\n",
    "\n",
    "[2 pt] For **custom NB**, what is the difference between the training and test accuracy? Give an explanation for why it might be so.\n",
    "    \n",
    "**Ans:**  The difference between training accuracy and test accuracy was approximately 8% in favor of the training accuracy. This might have happened due to overfitting - meaning that the model that we created was too focused on/parameterized to the training data and didn't generalize well. For example, it could have captured some noise in the training data that we did not want to be captured and included in the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2338897",
   "metadata": {},
   "source": [
    "### 3.2 change random_state\n",
    "Now, experiment with a range of random_state and respond to the following question.\n",
    "\n",
    "[2 pt] Does your responses to 3.1 change? If so, describe how your responses change and why you changed them.\n",
    "- (You do not need to artificially adjust your response to 3.1 to fit the any new findings you made after changing random_state)\n",
    "\n",
    "**Ans:** Yes my response to 3.1 changes because as the random state changes, the training accuracy is not significantly different than the testing accuracy. Therefore, I don't think overfitting is the reason training accuracy is higher than testing accuracy. If the reason that training accuracy is higher is overfitting, we would see overfitting regardless of what random_state we used. Instead, the reason that training accuracy is higher in random_state = 0 could be due to outliers, which we are susceptible to because we don't have a lot of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673e8f4",
   "metadata": {},
   "source": [
    "### 3.3 Choice of model\n",
    "[2 pt]  Compare **test** accuracy results for **custom NB and sklearn GNB**? Which model would you choose to use, and why? \n",
    "\n",
    "(There is no one right answer to your choice. A reasonable justification for your choice suffices.)\n",
    "\n",
    "**Ans:** I would choose sklearn GNB because it is pretty much the same accuracy and computationally more efficient. When we do custom NB, we are creating 12 gaussian KDEs and to create these 12 KDEs, we have to generate a normal pdf for every single data point. However, in sklearn GNB, we simply have to find the mean and standard deviation for each feature of each class and then create 12 normal pdf's from that data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed1fe16",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> Before submitting your hw, set train test split to random_state=0. Restart kernel and rerun all cells. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8852b55f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
